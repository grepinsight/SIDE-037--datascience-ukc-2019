---
title: "2019 UKC Prototype Study"
author: "Albert Lee"
date: "`r Sys.Date()`"
always_allow_html: yes
output:
  pdf_document:
  rmdformats::readthedown:
    code_folding: show
    lightbox: true
    gallery: true
    fig_caption: true
params:
  data: "NO_INPUT"
---

# Meta

**Author**: Albert Lee <br/>
**Date Created**: 2019-07-24 <br/>
**Date Updated**: `r Sys.Date()` </br>
**Environment** : </br>

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.align='center')
knitr::opts_chunk$set(cache=FALSE)
#knitr::opts_chunk$set(cache.lazy=FALSE)
```

# Introduction

* __Dataset__: https://data.cityofchicago.org/
* __Hackathon Note__:
  https://docs.google.com/document/u/1/d/1d8tgkLKcJwN7oy-W9h0R0IHJSFlz0H2tUJtG9LUn1hw/edit?ouid=101681315319651182806&usp=docs_home&ths=true
* __data description__: https://data.cityofchicago.org/api/views/ijzp-q8t2/rows.csv?accessType=DOWNLOAD


# Questions to ask

* What is the crime rate in chicago?
* What are the most useful predictors to predict the type of crime?
* Can we predict crime type using location and time information?
* etc


```{r libs, cache=FALSE, echo=FALSE}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(glue))
suppressPackageStartupMessages(library(here))
suppressPackageStartupMessages(library(plotly))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(tictoc))
suppressPackageStartupMessages(library(tidymodels))
suppressPackageStartupMessages(library(here))
suppressPackageStartupMessages(library(tictoc))
tic("Knitting the document")
```


# Data {#data}

## Crime data

* Issue: the dataset is huge. takes a long time to download (1.8G)


So will use the reduced version of it. See
```{r}
df_top10_samples <- read_rds(here::here("df_top10_samples.csv"))
df_top10_samples <- df_top10_samples %>%
  group_by(primary_type) %>%
  sample_n(1000) %>%
  ungroup()

df_top10_samples <- df_top10_samples %>%
  filter(primary_type %in% c("ASSAULT", "NARCOTICS"))

df_top10_samples %>%
count(primary_type)
```

```{r}
df_crime_types <- df_top10_samples %>%
  count(primary_type) %>%
  arrange(desc(n)) %>%
  mutate(`percent_crime` = scales::percent(n/sum(n)))

knitr::kable(df_crime_types)
```

## Location

## EDA: Is there a difference in crime type and rate at different times?

```{r}

df_top10_samples %>%
  select(primary_type, date) %>%
  mutate(time=hour(date)) %>%
  select(-date) %>%
  count(primary_type, time) %>%
  group_by(primary_type) %>%
  mutate(rate=n/sum(n)) %>%
  ungroup() %>%
  ggplot(aes(x=time, y=rate,
             color=primary_type,
             group=primary_type
             )) +
  geom_point() +
  geom_line() -> p
p
```




# Modeling - Machine Learning

## Feature engineering / Split

* long/lat and x_coord and y_coord contain the same information; will nust use the latter

```{r}
set.seed(628)

data_in <- df_top10_samples %>%
  mutate(hour=lubridate::hour(date)) %>%
  select(primary_type, x_coord, y_coord, hour, community_area, arrest) %>%
  mutate(arrest=as.factor(arrest)) %>%
  mutate(community_area =as.factor(community_area))

# Training/Testing Split --------------------
data_split <- initial_split(data_in, strata = "primary_type", p = 0.75)

train_data <- training(data_split)
test_data  <- testing(data_split)

model_rec <- recipe(primary_type ~ ., data = train_data) %>%
                step_center(x_coord,y_coord) %>%
                step_scale(x_coord,y_coord) %>%
                step_medianimpute(all_numeric()) %>%
                step_knnimpute(all_nominal()) %>%
                step_dummy(community_area, arrest)

summary(model_rec, original = FALSE)
```
```{r}
colnames(df_top10_samples)
```

## Preprocessing before machine learning

The following is the prepping done before fitting the ML model

```{r}
model_prepped <- prep(model_rec, training = train_data)
tidy(model_prepped)

juice(model_prepped) %>%
  head()
```

## Apply Preprocessing

> During the process of preparing the recipe, each step is estimated via prep and then applied to the training set using bake before proceeding to the next step.
> After the recipe has been prepared, bake can be used with any data set to apply the preprocessing to those data. <https://cran.r-project.org/web/packages/recipes/vignettes/Skipping.html>

```{r }
baked_train_data <- bake(model_prepped, new_data = train_data)
baked_test_data  <- bake(model_prepped, new_data = test_data)
```

```{r fitting}

model_knn <- nearest_neighbor(neighbors = 10) %>%
               set_engine("kknn")
model_rf <- rand_forest(trees = 1000) %>%
              # can increase the number of trees to fit better...
               set_engine("randomForest",
                          verbose = 2 # verbose = 1 means print evaluation metric
                          )
model_fit <- model_rf %>%
               set_mode("classification") %>%
               fit(formula(model_prepped),
                   data = baked_train_data)
print("done")
```

# Model Performance

```{r model_performance, dependson=c(-1)}
df_pred <- predict(model_fit, new_data=baked_test_data, type=c("prob")) %>%
  mutate(actual=baked_test_data$primary_type) %>%
  select(actual, everything())

# Cross entropy
if(length(unique(baked_test_data$primary_type)) > 2) {
  df_metrics_crossentropy <- df_pred %>%
      mn_log_loss(actual, 2:ncol(.))
} else{
  df_metrics_crossentropy <- df_pred %>%
      mn_log_loss(actual, 2)
}

# Accuracy and Kappa
df_pred_class <- predict(model_fit, new_data=baked_test_data, type=c("class")) %>%
  mutate(actual=baked_test_data$primary_type) %>%
  select(actual, everything())
df_metrics_classes <- metrics(df_pred_class, truth = actual, estimate=.pred_class)

bind_rows(df_metrics_classes, df_metrics_crossentropy)
```

```{r}
df_top10_samples %>%
  ggplot(aes(x=x_coord, y=y_coord, color=arrest)) +
  geom_point()
```
```{r}
df_top10_samples %>%
  select(arrest, primary_type) %>%
  table()
```

```{r}
if(model_fit$spec$method$libs == "randomForest") {
  randomForest::importance(model_fit$fit)
  plot(randomForest::importance(model_fit$fit))
}
```

# Conclusion


# Appendix

## IUCR

IUCR :
Illinois Uniform Crime Reporting (IUCR) codes are four digit codes that law enforcement agencies use to classify criminal incidents when taking individual reports. ... The Chicago Police Department currently uses more than 350 IUCR codes to classify criminal offenses, divided into “Index” and “Non-Index” offenses.

https://data.cityofchicago.org/Public-Safety/Chicago-Police-Department-Illinois-Uniform-Crime-R/c7ck-438e/data

## FBI code
FBI Code
Indicates the crime classification as outlined in the FBI's National Incident-Based Reporting System (NIBRS). See the Chicago Police Department listing of these classifications at http://gis.chicagopolice.org/clearmap_crime_sums/crime_types.html.
Plain Text

## Community area

Indicates the community area where the incident occurred. Chicago has 77 community areas. See the community areas at https://data.cityofchicago.org/d/cauq-8yn6.

# Session Information

```{r session_info, echo=FALSE}
sessionInfo()
```

# Time to Knit

```{r time_to_knit, echo=FALSE, cache=FALSE}
toc()
```

# Test


```{r}
df_top10_samples  %>%
  ggplot(aes(x=x_coord, y=long)) +
  geom_point()

df_top10_samples  %>%
  ggplot(aes(x=y_coord, y=lat)) +
  geom_point()
```


